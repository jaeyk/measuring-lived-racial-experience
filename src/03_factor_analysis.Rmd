---
title: "Factor analysis"
author: "Jae Yeon Kim"
output:
  html_document: 
    toc: true
    theme: united
---

#. Setup 

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework 
        ggthemes, # for fancy ggplot themes
        psych, # for psychological tools 
        factoextra, # for extracting and visualizing the results of multivariate data analyses 
        FactoMineR, # for multivariate exploratory data analysis and data mining
        conflicted, # for resolving conflicting functions
        ggthemes, # for fancy ggplot themes
        ggrepel, 
        here, # for self-contained projects
        ggpubr, # for pub-ready themes
        Hmisc, # for weighted mean and sd calculations
        janitor # for additional data cleaning
)


# Prefer select from dplyr 
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")

# for publication-friendly theme 
theme_set(theme_pubr())

source(here("functions", "utils.r"))
```

# Importing files 

Importing the file that we created in `02_imputation.Rmd`.

```{r}
imputed <- read.csv(here("processed_data/imputed.csv"))#[,-1] # No longer need to remove first column index if using new write.csv

# For Factor Analysis demonstration, we will use the first imputation.
# In a fully rigorous Bayesian framework, we might run FA on all 5 and pool, but that is complex for exploratory FA.
# We will use .imp == 1 for the structural analysis.
imputed_single <- imputed %>% filter(.imp == 1)
imputed <- imputed # Keep full imputed for later export
```
 
 
 # Selecting variables 
 
 I selected the variables related to the multi-dimensions of lived racial experience from the survey. This time, I renamed these variable names using the `rename function()` from the `dplyr` package, as they will appear in the plots I will soon create.
 
 ```{r}
 # Selecting variables 
 vars <- imputed_single %>% 
   select(matches("micro|discrim")) %>%
   select(-matches("index"))
```

## 3. Factor analysis 

### 3.1. Parallel analysis: How many factors?

- We assumed that there are two dimensions of lived racial experience. We do not observe these constructs from the survey data. Instead, we have a battery of survey items that might hang together and map onto the assumed conceptual framework. We can examine this pattern by calculating the covariance between survey items of interest. Factor analysis, by definition, is one way to perform this task, because factors are latent/unobserved/low dimensions in data. 
- Let's first check whether the assumption about the number of factors is valid. The `fa.parallel` function from the `psyche package` compares the eigenvalues of the correlation matrix ([the metric of variance explained]((https://sakaluk.wordpress.com/2016/05/26/11-make-it-pretty-scree-plots-and-parallel-analysis-using-psych-and-ggplot2/))) from the observed data with the eigenvalues generated from random data. In Figure 3, the Y-axis indicates eigenvalues, and the X-axis shows the number of possible factors from 1 to the maximum. Here, you can easily see that after three factors, the Y value drops immediately. 
- I set the `fm argument` in the `fa.parallel` function to “ml” (maximum likelihood estimation) to use the common factor model, which assumes that both “shared latent causes explain covariance between items” and “unexplained variable-specific variance” (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html)). Again, the result (again, an abrupt change in the slope) shows that assuming three factors is plausible.

```{r}
set.seed(1234)

fa.parallel(vars, 
    fm = 'ml', # eigenvalues using maximum likelihood (common factor model) 
    fa = 'fa', # principal axis factor analysis
    n.iter = 50, # number of iterations
    SMC = TRUE) 
```

### 3.2. Factor analysis 

- After validating the `nfactors = 2` assumption, I ran the factor analysis using the observed data. I assume that these factors are orthogonal by setting the `rotate  = ‘oblimin’.` For interpretation, this means the factors show the correlations between question items and factors (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html#looking-under-the-hood-of-the-fa-model)). 

```{r}
# Add grouping variable 
vars$race <- imputed_single$race

# Factor analysis 
# We run FA on the single imputation for structure discovery
vars_nested <- vars %>%
  group_by(race) %>%
  nest() %>%
  mutate(fa_res = map(data, ~run_fa(., use_poly = TRUE)), 
         fa_loadings = map(fa_res, df_fa_loadings),
         fa_weights = map(fa_res, df_fa_weights))
```

### 3.3. Data visualization

Here, the goal is to show how I visualized the relationship between each question item and three factors.

```{r}
vars_nested %>%
  unnest(fa_loadings) %>%
  filter(race != "Multiracial") %>%
  visualize_fa_loadings() +
  facet_grid(Factor~race)

ggsave(here("outputs/factor_analysis.png"), height = 10, width = 8)
```

# Creating composite variables 

I created composite variables by calculating the mean of survey items related to each estimated factor score.

## Export composite variables 

```{r}
# Add respondent ID
vars$respid <- imputed_single$respid

# NOTE: Factors were estimated on .imp==1.
# To compute scores for ALL imputations, we should ideally project the loadings onto all datasets.
# However, a simpler accepted approach is to use the raw mean scores of the items identified by FA.
# Since the composites are just rowMeans of specific items, we can calculate this for the full `imputed` dataframe.
 
# Create composite variables for the FULL imputed dataset
disc_vars <- names(vars %>% select(contains("disc")))
micro_vars <- names(vars %>% select(contains("micro")))

augmented_df <- imputed %>%
  mutate(
    discrimination = rowMeans(select(., all_of(disc_vars))),
    micro_aggression = rowMeans(select(., all_of(micro_vars)))
  )

# Final cleanup 
augmented_df <- janitor::clean_names(augmented_df)

# Save long format
write.csv(augmented_df, here("processed_data", "augmented_df.csv"), row.names = FALSE)
```

