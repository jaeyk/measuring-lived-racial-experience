---
title: "Factor analysis"
author: "Jae Yeon Kim"
output:
  html_document: 
    toc: true
    theme: united
---

#. Setup 

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework 
        ggthemes, # for fancy ggplot themes
        psych, # for psychological tools 
        factoextra, # for extracting and visualizing the results of multivariate data analyses 
        FactoMineR, # for multivariate exploratory data analysis and data mining
        tidytext, # facet-safe reordering for loadings plot
        conflicted, # for resolving conflicting functions
        ggthemes, # for fancy ggplot themes
        ggrepel, 
        here, # for self-contained projects
        ggpubr, # for pub-ready themes
        Hmisc, # for weighted mean and sd calculations
        janitor # for additional data cleaning
)


# Prefer select from dplyr 
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")

# for publication-friendly theme 
theme_set(theme_pubr())

source(here("functions", "utils.r"))
```

# Importing files 

Importing the file that we created in `02_imputation.Rmd`.

```{r}
imputed <- read.csv(here("processed_data/imputed.csv"))#[,-1] # No longer need to remove first column index if using new write.csv

# For Factor Analysis demonstration, we will use the first imputation.
# In a fully rigorous Bayesian framework, we might run FA on all 5 and pool, but that is complex for exploratory FA.
# We will use .imp == 1 for the structural analysis.
imputed_single <- imputed %>% filter(.imp == 1)
imputed <- imputed # Keep full imputed for later export
```
 
 
 # Selecting variables 
 
 I selected the variables related to the multi-dimensions of lived racial experience from the survey. This time, I renamed these variable names using the `rename function()` from the `dplyr` package, as they will appear in the plots I will soon create.
 
```{r}
# Selecting variables 
vars <- imputed_single %>% 
  select(matches("micro|discrim")) %>%
  select(-matches("index"))

# Human-readable labels for survey items (for reader-facing figures/tables)
item_label_map <- c(
  "discrim_hired" = "Not hired",
  "discrim_promotion" = "Passed over for promotion",
  "discrim_fired" = "Fired",
  "discrim_housing" = "Housing discrimination",
  "discrim_police" = "Police mistreatment",
  "discrim_neighbor" = "Hostility from neighbors",
  "micro_honest" = "Treated as if dishonest",
  "micro_afraid" = "Others acted afraid",
  "micro_namecall" = "Called names/insulted",
  "micro_harassed" = "Harassed or threatened",
  "micro_english" = "Assumed poor English",
  "micro_service" = "Received poorer service",
  "micro_creative" = "Assumed not creative",
  "micro_pronounce" = "Name mispronounced",
  "micro_stem" = "Stereotyped as STEM-strong"
)
```

## 3. Factor analysis 

### 3.1. Parallel analysis: How many factors?

- We assumed that there are two dimensions of lived racial experience. We do not observe these constructs from the survey data. Instead, we have a battery of survey items that might hang together and map onto the assumed conceptual framework. We can examine this pattern by calculating the covariance between survey items of interest. Factor analysis, by definition, is one way to perform this task, because factors are latent/unobserved/low dimensions in data. 
- Let's first check whether the assumption about the number of factors is valid. The `fa.parallel` function from the `psyche package` compares the eigenvalues of the correlation matrix ([the metric of variance explained]((https://sakaluk.wordpress.com/2016/05/26/11-make-it-pretty-scree-plots-and-parallel-analysis-using-psych-and-ggplot2/))) from the observed data with the eigenvalues generated from random data. In Figure 3, the Y-axis indicates eigenvalues, and the X-axis shows the number of possible factors from 1 to the maximum. Here, you can easily see that after three factors, the Y value drops immediately. 
- I set the `fm argument` in the `fa.parallel` function to “ml” (maximum likelihood estimation) to use the common factor model, which assumes that both “shared latent causes explain covariance between items” and “unexplained variable-specific variance” (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html)). Again, the result (again, an abrupt change in the slope) shows that assuming three factors is plausible.

```{r}
set.seed(1234)

fa.parallel(vars, 
    fm = 'ml', # eigenvalues using maximum likelihood (common factor model) 
    fa = 'fa', # principal axis factor analysis
    n.iter = 50, # number of iterations
    SMC = TRUE) 
```

### 3.2. Factor analysis 

- After validating the `nfactors = 2` assumption, I ran the factor analysis using the observed data. I assume that these factors are orthogonal by setting the `rotate  = ‘oblimin’.` For interpretation, this means the factors show the correlations between question items and factors (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html#looking-under-the-hood-of-the-fa-model)). 

```{r}
# Add grouping variable 
vars$race <- imputed_single$race

# Factor analysis 
# We run FA on the single imputation for structure discovery
vars_nested <- vars %>%
  group_by(race) %>%
  nest() %>%
  mutate(fa_res = map(data, ~run_fa(., use_poly = TRUE)), 
         fa_loadings = map(fa_res, df_fa_loadings),
         fa_weights = map(fa_res, df_fa_weights))
```

### 3.3. Data visualization

Here, the goal is to inspect race-specific loading patterns. This detailed plot is saved as a supplemental figure.

```{r}
vars_nested %>%
  unnest(fa_loadings) %>%
  filter(abs(Loading) >= 0.20) %>%
  filter(race != "Multiracial") %>%
  visualize_fa_loadings() +
  facet_grid(Factor~race, scales = "free_y", space = "free_y") +
  labs(
    subtitle = "Race-specific EFA loadings (2-factor oblimin rotation)",
    caption = "Used to define item groupings for constructs. Composite scores are unweighted item means. Source: National Asian American Survey (2016)"
  )

ggsave(here("outputs/factor_analysis_full.png"), height = 10, width = 8)
```

# Creating composite variables 

I created composite variables using an explicit loading-based assignment rule. Items with high cross-loadings are excluded before scoring.

## Export composite variables 

```{r}
# Add respondent ID
vars$respid <- imputed_single$respid

# NOTE: Factors were estimated on .imp==1.
# Build a global item-to-factor mapping from race-specific loadings:
# 1) average absolute loading by item x factor across races
# 2) keep items with primary loading >= 0.30
# 3) drop high cross-loaders (primary-secondary < 0.10)
load_map <- vars_nested %>%
  unnest(fa_loadings) %>%
  filter(race != "Multiracial") %>%
  group_by(Measures, Factor) %>%
  summarise(
    mean_loading = mean(Loading, na.rm = TRUE),
    mean_abs_loading = mean(abs(Loading), na.rm = TRUE),
    .groups = "drop"
  )

item_assignment <- load_map %>%
  group_by(Measures) %>%
  arrange(desc(mean_abs_loading), .by_group = TRUE) %>%
  mutate(rank = row_number()) %>%
  summarise(
    assigned_factor = Factor[1],
    primary_loading = mean_abs_loading[1],
    secondary_loading = mean_abs_loading[2],
    loading_gap = primary_loading - secondary_loading,
    .groups = "drop"
  ) %>%
  mutate(
    keep = primary_loading >= 0.30 & loading_gap >= 0.10
  )

# Keep only well-separated items per factor
disc_vars <- item_assignment %>%
  filter(keep, assigned_factor == "Discrimination") %>%
  pull(Measures)

micro_vars <- item_assignment %>%
  filter(keep, assigned_factor == "Micro-aggression") %>%
  pull(Measures)

# Export mapping for transparency
item_assignment_labeled <- item_assignment %>%
  mutate(
    measure_label = recode(Measures, !!!item_label_map, .default = Measures)
  )

write.csv(item_assignment_labeled, here("outputs", "fa_item_assignment.csv"), row.names = FALSE)

# Main reader-facing figure: only retained items used for scoring
kept_plot_df <- item_assignment %>%
  filter(keep) %>%
  mutate(
    measure_label = recode(Measures, !!!item_label_map, .default = Measures),
    measure_label = stringr::str_wrap(measure_label, width = 28),
    measure_label = tidytext::reorder_within(measure_label, primary_loading, assigned_factor)
  )

p_kept <- kept_plot_df %>%
  ggplot(aes(x = measure_label, y = primary_loading, fill = assigned_factor)) +
  geom_col(width = 0.7) +
  coord_flip() +
  tidytext::scale_x_reordered() +
  facet_wrap(~assigned_factor, ncol = 1, scales = "free_y") +
  scale_fill_grey(start = 0.35, end = 0.75) +
  labs(
    title = "Construct measures retained for scoring",
    subtitle = "Items retained by loading rule: primary >= 0.30 and loading gap >= 0.10",
    x = "Survey items",
    y = "Primary loading (mean absolute across races)",
    fill = "Construct",
    caption = "Source: National Asian American Survey (2016)"
  ) +
  theme_pubr(base_size = 11) +
  theme(legend.position = "bottom")

ggsave(here("outputs", "factor_analysis.png"), p_kept, height = 7, width = 8)

augmented_df <- imputed %>%
  mutate(
    discrimination = rowMeans(select(., all_of(disc_vars)), na.rm = TRUE),
    micro_aggression = rowMeans(select(., all_of(micro_vars)), na.rm = TRUE)
  )

# Final cleanup 
augmented_df <- janitor::clean_names(augmented_df)

# Save long format
write.csv(augmented_df, here("processed_data", "augmented_df.csv"), row.names = FALSE)
```
