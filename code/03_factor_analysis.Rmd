---
title: "Factor analysis"
author: "Jae Yeon Kim"
output:
  html_document: 
    toc: true
    theme: united
---

#. Setup 

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework 
        ggthemes, # for fancy ggplot themes
        psych, # for psychological tools 
        factoextra, # for extracting and visualizing the results of multivariate data analyses 
        FactoMineR, # for multivariate exploratory data analysis and data mining
        conflicted, # for resolving conflicting functions
        ggthemes, # for fancy ggplot themes
        here, # for self-contained projects
        ggpubr, # for pub-ready themes
        Hmisc, # for weighted mean and sd calculations
        jantior # for additional data cleaning 
)


# Prefer select from dplyr 
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")

# for publication-friendly theme 
theme_set(theme_pubr())

source(here("functions", "utils.r"))
```

# Importing files 

Importing the file that we created in `02_imputation.Rmd`.

```{r}
imputed <- read.csv(here("processed_data/imputed.csv"))[,-1]
```


# Selecting variables 

I selected the variables related to the multi-dimensions of lived racial experience from the survey. This time, I renamed these variable names using the `rename function()` from the `dplyr` package, as they will appear in the plots I will soon create.

```{r}
# Selecting variables 
vars <- imputed %>% 
  select(matches("micro|discrim")) %>%
  select(-matches("index"))
```

## 3. Factor analysis 

### 3.1. Parallel analysis: How many factors?

- We assumed that there are two dimensions of lived racial experience. We do not observe these constructs from the survey data. Instead, we have a battery of survey items that might hang together and map onto the assumed conceptual framework. We can examine this pattern by calculating the covariance between survey items of interest. Factor analysis, by definition, is one way to perform this task, because factors are latent/unobserved/low dimensions in data. 
- Let's first check whether the assumption about the number of factors is valid. The `fa.parallel` function from the `psyche package` compares the eigenvalues of the correlation matrix ([the metric of variance explained]((https://sakaluk.wordpress.com/2016/05/26/11-make-it-pretty-scree-plots-and-parallel-analysis-using-psych-and-ggplot2/))) from the observed data with the eigenvalues generated from random data. In Figure 3, the Y-axis indicates eigenvalues, and the X-axis shows the number of possible factors from 1 to the maximum. Here, you can easily see that after three factors, the Y value drops immediately. 
- I set the `fm argument` in the `fa.parallel` function to “ml” (maximum likelihood estimation) to use the common factor model, which assumes that both “shared latent causes explain covariance between items” and “unexplained variable-specific variance” (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html)). Again, the result (again, an abrupt change in the slope) shows that assuming three factors is plausible.

```{r}
set.seed(1234)

fa.parallel(vars, 
    fm = 'ml', # eigenvalues using maximum likelihood (common factor model) 
    fa = 'fa', # principal axis factor analysis
    n.iter = 50, # number of iterations
    SMC = TRUE) 
```

### 3.2. Factor analysis 

- After validating the `nfactors = 2` assumption, I ran the factor analysis using the observed data. I assume that these factors are orthogonal by setting the `rotate  = ‘oblimin’.` For interpretation, this means the factors show the correlations between question items and factors (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html#looking-under-the-hood-of-the-fa-model)). 

```{r}
# Add grouping variable 
vars$race <- imputed$race

# Factor analysis 
vars_nested <- vars %>%
  group_by(race) %>%
  nest() %>%
  mutate(fa_res = map(data, run_fa), 
         fa_loadings = map(fa_res, df_fa_loadings),
         fa_weights = map(fa_res, df_fa_weights))
```

### 3.3. Data visualization

Here, the goal is to show how I visualized the relationship between each question item and three factors.

```{r}
vars_nested %>%
  unnest(fa_loadings) %>%
  filter(race != "Multiracial") %>%
  visualize_fa_loadings() +
  facet_grid(Factor~race)

ggsave(here("outputs/factor_analysis.png"), height = 10, width = 8)
```

# Creating composite variables 

I created composite variables by calculating the mean of survey items related to each estimated factor score.

## Non-weighted 

```{r}
base <- vars_nested %>%
  select(!matches("fa")) %>%
  unnest(data) %>%
  pivot_longer(c(-1), 
               names_to = "Variables", 
               values_to = "Scores") %>%
  group_by(race, Variables)

non_weighted_summary <- group_summarize(base, "Non-weighted")
```

## Weighted 

```{r}
weighted_summary <- group_summarize_weight(base, vars_nested, "Weighted")
```

## Bind them together 

```{r}
weighted_comparison <- bind_rows(non_weighted_summary, weighted_summary)
```

## 6. Data visualization 

```{r}
weighted_comparison %>%
    filter(race != "Multiracial") %>%
    ggplot(aes(x = reorder(dimension, mean), y = mean, ymax = upper.ci, ymin = lower.ci)) +
        geom_pointrange(size = 0.7) +  # point estimates plus confidence intervals 
        coord_flip() +
        labs(title = "Average and Weighted Average Responses by Two Dimensions of Marginalization",
             y = "Average score of survey responses", x = "Estimated factor scores",
             caption = "Source: National Asian American Survey (2016)") +
        facet_grid(race~Type)

ggsave(here("outputs/weighted_responses.png"), width = 10)
```

## Export composite variables 

```{r}
# Add respondent ID
vars$respid <- imputed$respid

# Extract factor weights by race
final_base <- vars_nested %>%
  select(-c(fa_res, fa_loadings, data)) %>%
  unnest(fa_weights)

# Create composite variables 
disc <- final_base %>% 
  filter(str_detect(Measures, "disc")) %>%
  filter(Factor == "Discrimination") 
     
microagg <- final_base %>% 
  filter(str_detect(Measures, "micro")) %>%
  filter(Factor != "Discrimination") 

final_base <- bind_rows(disc, microagg)
```


```{r}
new_vars <- left_join(vars %>%
  pivot_longer(c(1:13), 
               names_to = "Measures", 
               values_to = "Scores"),
  final_base) %>%
  group_by(race, respid, Factor) %>%
  mutate(mean = Hmisc::wtd.mean(Scores, Weights)) %>%
  select(-c(Measures, Scores, Weights)) %>%
  dplyr::distinct_all() %>%
  pivot_wider(names_from = "Factor",
              values_from = "mean")
```


```{r}
# Create a complete dataframe 
full_vars <- left_join(vars, imputed) 

# Add new variables
augmented_df <- left_join(full_vars, new_vars)

# Final cleanup 
augmented_df <- janitor::clean_names(augmented_df)

write.csv(augmented_df, here("processed_data", "augmented_df.csv"))
```

