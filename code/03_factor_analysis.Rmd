---
title: "Factor analysis"
author: "Jae Yeon Kim"
output:
  html_document: 
    toc: true
    theme: united
---

## 0. Setup 

I tweaked the global option of the R Markdown to resize figures produced by ggplot2.

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, 
                      echo = FALSE, warning = FALSE, message = FALSE) # global setting for enlarging image size
```

```{r}

# Clean up the environment

# rm(list = ls())

# Import libraries (adapted from this link: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework 
        ggthemes, # for fancy ggplot themes
        psych, # for psychological tools 
        factoextra, # for extracting and visualizing the results of multivariate data analyses 
        FactoMineR, # for multivariate exploratory data analysis and data mining
        conflicted, # for resolving conflicting functions
        ggthemes, # for fancy ggplot themes
        here, # for self-contained projects
        ggpubr # for pub-ready themes 
)

devtools::install_github("jaeyk/makereproducible",
        dependencies = TRUE)
        
library(makereproducible)

# for publication-friendly theme 
theme_set(theme_pubr())

# Prefer select from dplyr 
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")

```

## 1. Importing files 

Importing the file that we created in `02_imputation.Rmd`.

```{r}

# Import 

imputed <- read.csv("/home/jae/analyzing-racial-lived-experience/processed_data/imputed.csv")[,-1] %>% # Ignore the first column 
    filter(race == "AAPI")

```


## 2. Selecting variables 

- I selected the variables related to the multi-dimensions of lived racial experience from the survey. This time, I renamed these variable names using the `rename function()` from the `dplyr` package, as they will appear in the plots I will soon create.

```{r}

# Selecting variables 

vars <- imputed %>%
    select(q5_1_b, q5_1_c, q5_1_d, q5_1_e, q5_1_g, q5_1_h, q5_1_i, # micro-aggression 
                  q5_2_a, q5_2_b, q5_2_c, q5_2_d, q5_2_e, q5_2_f, # discrimination
                  q5_7_a, q5_7_b, q5_7_c, q5_7_d, q5_7_e, q5_7_f, q5_7_g, q5_7_h, q5_7_i, q5_7_j, q5_7_k, q5_7_l) # everyday challenge 

```

```{r}

# Renaming these variables 

vars <- vars %>%
    rename(# micro-agression
        service_unfriendly = q5_1_b,
        english_proficiency = q5_1_c,
        afraid_of_you = q5_1_d,
        thought_dishonest = q5_1_e,
        insulted = q5_1_g,
        threatened = q5_1_h,
        name_mispronounced = q5_1_i,
        
        # discrimination 
        promotion_denied = q5_2_a,
        unfairly_fired = q5_2_b,
        job_rejected = q5_2_c,
        policy_brutality = q5_2_d,
        housing_discrimination = q5_2_e,
        neighbor_hostility = q5_2_f,
        
        # everyday challenge
        visa_delay = q5_7_a,
        school_quality = q5_7_b,
        school_bullied = q5_7_c,
        college_affordability = q5_7_d,
        elderly_care = q5_7_e,
        medical_care = q5_7_f,
        rent_affordability = q5_7_g,
        college_debt = q5_7_h,
        medical_debt = q5_7_i,
        card_debt = q5_7_j,
        child_care = q5_7_k,
        little_saving = q5_7_l)

```

## 3. Factor analysis 

### 3.1. Parallel analysis: How many factors?

- We assumed assumed that there are three dimensions of lived racial experience. We do not observe these constructs from the survey data. What we have instead is a battery of survey items that might hang together and map onto the assumed conceptual framework. We can examine this pattern by calculating the covariance between survey items of interest. Factor analysis, by definition, is one way to perform this task, because factors are latent/unobserved/low dimensions in data. 
- Let’s first check whether the assumption about the number of factors is valid. The `fa.parallel` function from the `psyche package` compares the eigenvalues of the correlation matrix ([the metric of variance explained]((https://sakaluk.wordpress.com/2016/05/26/11-make-it-pretty-scree-plots-and-parallel-analysis-using-psych-and-ggplot2/))) from the observed data with the eigenvalues generated from random data. In Figure 3, the Y-axis indicates eigenvalues and the X-indicates the number of possible factors from 1 to the maximum. Here, you can easily see that after three factors, the Y value drops immediately. 
- I set the `fm argument` in the `fa.parallel` function to “ml” (maximum likelihood estimation) to use the common factor model, which assumes that covariance between items is explained by both “shared latent causes” and “unexplained variable-specific variance” (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html)). The result (again, an abrupt change in the slope) shows that assuming three factors is plausible.

```{r}

set.seed(1234)

fa.parallel(vars, 
    fm = 'ml', # eigenvalues using maxium likelihood (common factor model) 
    fa = 'fa', # principal axis factor analysis
    n.iter = 50, # number of iterations
    SMC = TRUE) 

```

### 3.2. Factor analysis 

- After validating the `nfactors = 3` assumption, I ran the factor analysis using the observed data. I assume that these factors are orthogonal by setting the `rotate  = ‘oblimin’.` For interpretation, this means the factors show the correlations between question items and factors (for more information, see this [link](https://psu-psychology.github.io/psy-597-SEM/06_factor_models/factor_models.html#looking-under-the-hood-of-the-fa-model)). 

```{r}

# Factor analysis 
factor_analysis <- fa(vars, 
                   nfactors = 3, # three factors  
                   rotate = 'oblimin', 
                   fm = 'ml') # ML estimation 

# Summary 
summary(factor_analysis)

```

### 3.3. Data visualization

Here, the goal is to show how I visualized the relationship between each question item and three factors. I did this in two steps. I first extracted factor loadings (correlation coefficients between observed data and factors) and then put them into a dataframe. 

```{r}

# Extract factor loadings 
factor_frame <- factor_analysis$loadings %>%
                 unclass() %>%
                 as.data.frame()

# Putting them into a data frame
factor_df <- data.frame(Measures = rownames(factor_frame), 
              everyday_challenge = factor_frame$ML1,
              micro_aggression = factor_frame$ML2,
              discrimination = factor_frame$ML3)

```

Next, I visualized the relationship between factor loadings and the three factors.

```{r}

factor_df %>%
    gather(key = "Factor", value = "Loading", 
           everyday_challenge:discrimination) %>%
    ggplot(aes(x = factor(Measures, levels = factor_df$Measures), y = Loading, fill = Loading)) +
        geom_bar(stat = "identity") +
        coord_flip() +
        facet_wrap(~Factor, nrow = 1) +
        scale_fill_gradient2(name = "Loading",
                             high = "blue", mid = "white", low = "red", midpoint = 0, guide = F) +
          labs(y= "Loading Strength", x = "Measures",
               title = "Factor Analysis Results",
               subtitle = "Only included Asian Americans",
               caption = "Source: National Asian American Suvrey (2016)")

ggsave(make_here("/home/jae/analyzing-racial-lived-experience/outputs/factor_analysis.png"), height = 6, width = 8)

```

## 4. Creating index variables 

I created index variables by calculating the mean of survey items related to each factor. I dropped the `name_mispronounced` variable in doing this because its factor loading is extremely low.

```{r}

# Micro-aggression

micro_aggression <- vars %>% 
    select(service_unfriendly,
        english_proficiency,
        afraid_of_you,
        thought_dishonest,
        insulted,
        threatened,
        name_mispronounced) %>%
    summarise_all(funs(mean)) %>%
    gather(Measurees, micro_aggression_avg, c(1:7))

# Discrimination 

discrimination <- vars %>% 
    select(promotion_denied,
        unfairly_fired,
        job_rejected,
        policy_brutality,
        housing_discrimination,
        neighbor_hostility) %>%
    summarise_all(funs(mean)) %>%
    gather(Measurees, discrimination_avg, c(1:6))

# Everyday challenge

everyday_challenge <- vars %>% 
    select(visa_delay,
        school_quality,
        school_bullied,
        college_affordability,
        elderly_care,
        medical_care,
        rent_affordability,
        college_debt,
        medical_debt,
        card_debt,
        child_care,
        little_saving) %>%
    summarise_all(funs(mean)) %>%
    gather(Measurees, micro_aggression_avg, c(1:12))

```


## 5. Replacing the survey items with the index variables. 

I then replaced the survey items related to lived racial experience with the three index variables (weighted average responses).

```{r}

# Replace old questions 

factored <- rbind(data.frame("Weighted" = 
factor_df$micro_aggression[1:7] * micro_aggression[,2]),
                  data.frame("Weighted" = factor_df$discrimination[8:(8+5)] * discrimination[,2]),
                  data.frame("Weighted" = factor_df$everyday_challenge[(8+6):(8+6+11)] * everyday_challenge[,2]))
                  
factored$factor <- c(rep("micro_aggression", 7), rep("discrimination", 6), rep("everyday_challenge", 12))

# Non-weighted average responses 

non_factored <- data.frame("Non_weighted" = vars %>% 
    summarise_all(funs(mean)) %>% as.numeric(),
                           "factor" = c(rep("micro_aggression", 7), rep("discrimination", 6), rep("everyday_challenge", 12)))

# Merge them 

weighted_comparison <- merge(factored, non_factored) %>%
    gather(weighted, value, Weighted:Non_weighted)

```

## 6. Data visualization 

```{r}


weighted_comparison %>%
    group_by(factor, weighted) %>% # group to summarize
    summarise(mean = mean(value), # summarize mean, standard deviation, and n 
              sd = sd(value),
              n = n()) %>%
    mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals 
           lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
           upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
    ggplot(aes(x = reorder(factor, mean), y = mean, ymax = upper.ci, ymin = lower.ci, color = weighted)) +
        geom_pointrange(size = 0.7) + # point estimates plus confidence intervals 
        theme_base() +
        coord_flip() +
        labs(title = "Three Dimensions of Lived Racial Experience",
             subtitle = "Only included Asian Americans",
             y= "Average score of survey responses", x = "Factor",
             caption = "Source: National Asian American Suvrey (2016)",
             col = "Weighted")

ggsave(make_here("/home/jae/analyzing-racial-lived-experience/outputs/weighted_responses.png"), width = 10)

```