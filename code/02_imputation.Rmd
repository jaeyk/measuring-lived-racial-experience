---
title: "Imputation"
author: "Jae Yeon Kim"
output:
  html_document: 
    toc: true
    theme: united
---

# Setup 

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        remotes, # for installing packages on GitHub 
        mice, # for imputation
        miceadds, # additional functions for mice
        tidyverse, # for the tidyverse framework 
        naniar, # for missing values 
        MissMech, # testing patterns among missing values 
        ggthemes, # for fancy ggplot themes
        here, # for self-contained projects
        ggpubr # for pub-ready themes 
)

source(here("functions", "utils.r"))

remotes::install_github("njtierney/naniar")

# for publication-friendly theme 
theme_set(theme_pubr())
```

# Importing files 

Importing the file that we created in `01_data_cleaning.Rmd`.

```{r}
# Import 

cleaned <- read.csv(here("processed_data/cleaned.csv"))

cleaned$X <- NULL
```

# Examining missing responses

- Listwise deletion (`na.rm = TRUE`) works only if these observations are missing completely at random (MCAR). This is a strong assumption, as it happens very rarely. 

## Exploratory analysis (data visualization)

- The `nanair package` provides many valuable functions for inspecting missing data values. I used the `miss_var_summary() function` from this package to check the missing pattern and visualized it using ggplot2. 
- `q10_2b` education is seriously missing observations (>75%) for whites, blacks, and multiracial Americans but not for Asian American Pacific Islanders (AAPI) and Latinos. 
- More or less 50% missingness exists among everyday challenged related variables (starts with `q5_7`) across all racial groups. This is because respondents were asked about this construct using different questions.

```{r}
# Visualize the percentage of missing values by variables and subgroups 

cleaned %>%
    group_by(race) %>% # group by race
    miss_var_summary() %>% # summary 
    filter(n_miss != 0) %>% # show variables that include missing values
    ggplot(aes(x = reorder(variable, pct_miss), y = pct_miss)) +
        geom_col() +
        facet_wrap(~race) + # facet by race 
        coord_flip() # flip axes 

ggsave(here("outputs/missing_rate.png"), height = 8)
```

# Multiple imputation 

In this case, I took a multiple imputation approach. I recovered (imputed) missing values based on the observed data. I did so by making simulations of these imputed values to garner some uncertainty measures.

## Imputing data 

In this project, I used the `mice package` developed by [Stef van Buuren](https://stefvanbuuren.name/).  The following code shows how the imputation model is set up. I comment on each argument to make it explicit how the model is set up. For instance, the `m argument` refers to the number of imputations, and I set it to `5`.

```{r}
imp <- mice(
  cleaned %>% select(-respid),
    seed = 1234, # for reproducibility
    m = 5, # the number of imputations
    maxit = 10, # the max number of iterations 
    method = "pmm", # predictive mean method
    print = FALSE) 
```

## Evaluating imputations

### Data visualization 

The goal of imputation is to create imputed values that are as close as possible to observed values. I used the `densityplot() function` from the `mice package` to display the kernel density estimates (KDE) for the marginal distribution of the imputed (red) and the observed (blue) values. Kernel density estimation is calculated by weighting the distance of the data points. The plot shows that the distributions of the imputed and observed values are pretty close, especially among items on a Likert scale. 

```{r}
densityplot(imp, layout = c(1, 3))
```
## Pooling results

```{r}
# Pooling results 
imputed <- mice::complete(imp) # the first imputed data

# Check 
paste("The number of missing values in the data after multiple imputation is", sum(is.na(imputed)))
```

# the imputed data

```{r}
imputed$respid <- cleaned$respid

write.csv(imputed, here("processed_data/imputed.csv"))
```
