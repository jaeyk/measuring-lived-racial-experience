---
title: "Imputation"
author: "Jae Yeon Kim"
output:
  html_document: 
    toc: true
    theme: united
---

## 0. Setup 

```{r}

# Clean up the environment

# rm(list = ls())

# Import libraries (adapted from this link: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        mice, # for imputation
        miceadds, # additional functions for mice
        tidyverse, # for the tidyverse framework 
        naniar, # for missing values 
        MissMech, # testing patterns among missing values 
        BaylorEdPsych, # testing patterns among missing values
        SuperLearner, # for choosing a weighted combination of different algorithms 
        ggthemes # for fancy ggplot themes
)

```

## 1. Importing files 

Importing the file that we created in `01_data_cleaning.Rmd`.

```{r}

# Import 

scaled <- read.csv("/home/jae/analyzing-racial-lived-experience/processed_data/scaled.csv")[,-1] # ignore the first column (=row numbers)

```

## 2. Examining missing responses

- Unless we completely missed responses/observations/values by random, or missing completely at random (MCAR), the missing values are related to the data. Under this condition, if researchers ignore missing values using listwise deletion (e.g., `na.rm = TRUE`), especially when the percentage of missing values is large, this practice causes biased estimators. 

### 2.1. Exploratory analysis (data visualization)

To examine the nature of missigness in the data, let's first take a look at how many missing values exist and where we can find them. The bar plot shows the degree of missingness faceted by racial groups. I did that because we believe race is a key moderating variable.

- `q10_2b` education is seriously missing (>75%) for whites, blacks, and multiracial Americans but not for Asian American Pacific Islanders (AAPI) and Latinos. 
- More or less 50% missingness exist among everyday challenged related variables (starts with `q5_7`) for all racial groups.

```{r}

# Visualize the percentaeg of missing values by variables and subgroups 

scaled %>%
  group_by(race) %>% # group by race
  miss_var_summary() %>% # summary 
  filter(n_miss != 0) %>% # show variables that include missing values
  ggplot(aes(x = reorder(variable, pct_miss), y = pct_miss)) +
    geom_col() +
    theme_fivethirtyeight() +
    facet_wrap(~race) + # facet by race 
    coord_flip() # flip axes 

ggsave("/home/jae/analyzing-racial-lived-experience/outputs/missing_rate.png")
```

### 2.2. Little's Test 

Now, let's formally test whether the data misses values by random. Here, I used [Roderik J. A. Little's global test for MCAR](https://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478722?casa_token=xXGRTDzkeB4AAAAA:Ji89bNk4Sh9VXEoEJrEl89Iv3JrH2s0onf4gfOz4TEb1rB9DAkVJUyVc7eU9LDYVuhIaxkBZ9uQS) which he published in the Journal of Statistical Association in 1988. The null hypothesis is the data is MCAR. The test result shows that p-value is 0.7325409 and, thus, we can safely assume that the probability of rejecting the null hypothesis (not MCAR) is extremely low.

```{r eval=FALSE, include=FALSE}

little_test_result <- scaled %>%
 LittleMCAR()

little_test_result$p.value

```


## 3. Multiple imputation 

One solution to missing values is to impute them based one the observed data. Here, the key insight is shifting analytic focus from estimating the best imputed value to creating multiple imputed data using simulations. Researchers then select a model that best fits the missed to the observed components of the data ([Rubin 1976](https://journals.sagepub.com/doi/pdf/10.3102/10769986002001001?casa_token=VmQAcENEd1oAAAAA:izsSioksnO9anDaSrhyDRQzi78E4tMvY_84xinVx6N1vayowbmsyBtgEU4iS-sMnf07F5ixyFbam). This is a better strategy to deal with uncertainty surrounding the model selection.

### 3.1. Imputing data 

In this project, I used the `mice package` in R for multiple implication, which was developed by [Stef van Buuren](https://stefvanbuuren.name/). His book titled [Flexible Imputation of Missing Data](https://stefvanbuuren.name/fimd/) is a great resource for conducting imputation in R. Using the `mice function` from the package, I created five imputed data. [Applied Missing Data Analaysis with SPSS and (R)Studio](https://bookdown.org/mwheymans/bookmi/) (Heymans and Eekhout 2019) is another great resource.

```{r}

imp <- mice(scaled,
     seed = 1234, # for reproducibility
     m = 5, # the number of imputations
     maxit = 10, # the max numbe of iterations 
     method = "pmm", # predictive mean method
     print = FALSE) 

```

### 3.2. Evaluating imputations

#### 3.2.1. Data visualization 

To evaluate imputations, I first measured the discrepancy between the distribution of imputed and that of observed values. If we assume missing at random (MAR, not completely random but still can be explained by certain variables), these distributions [do not need to be identicial](https://stefvanbuuren.name/fimd/sec-diagnostics.html), but they still should look similar.

I used the `function densityplot()` from the `mice package` to display the kernel density estimates for the marginal distribution of the imputed (`red`) and observed values (`blue`). Kernel density estimation is calculated by weighting the distances of the data points. The plots show that the distributions of the imputed and observed values are quite close especially among itmes on a likert scale. 


```{r}

densityplot(imp, layout = c(1, 3))

```

#### 3.2.2. Rubin's rule test 

Another critical test is whether model fit changes depending on which imputed data we select. To examine this, I built a simple regression model, which is based on the idea that survey questions on everyday challenge should be strongly linearly associated. In addition, this case is nice as we found many missing values in these variables in the earlier exploratory analysis. I did Rubin's rule test using the `pool() function` from the `mice package`. The test "averages the estimates of the complete model" and "computes the total variance over the repeated analyse" (for more information, see [this function documentation](https://rdrr.io/cran/mice/man/pool.html)). The summary test result shows that the p-values for the regression coefficients are extremely small, which implies selecting one model over the other does make little difference (within imputation variance) for the model fit. One assumption for Rubin's rule test is the distribution of the data follows a normal distribution. Shapiro-Wilk test examines the correlation between the data and the corresponding normal scores and its result supports this assumption.

```{r}

# Select test variables from the original data 

test_vars <- imp$data %>%
  dplyr::select(q5_7_a, q5_7_b, q5_7_c, q5_7_d, q5_7_e, q5_7_f, q5_7_g, q5_7_h, q5_7_i, q5_7_j, q5_7_k, q5_7_l)

# Shapiro test 

apply(test_vars, 2, shapiro.test)

# Fitting the data to the OLS regression model

fit <- with(data = imp, expr = lm(q5_7_a ~ # visa delay 
    q5_7_b + # school quality 
    q5_7_c + # school bullied 
    q5_7_d + # college affordability 
    q5_7_e + # elderly care 
    q5_7_f + # medical care
    q5_7_g + # rent affordability 
    q5_7_h + # college debt
    q5_7_i + # medical debt 
    q5_7_j + # card debt
    q5_7_k + # childcare 
    q5_7_l)) # little saving  

```

```{r}

# Pooling them together

comb_fit <- pool(fit)

summary(comb_fit)

```

### 3.4. Pooling results

```{r}
# Pooling results 

imputed <- mice::complete(imp) # the first imputed data

# Check 

paste("The number of missing values in the data after multiple imputation is", sum(is.na(imputed)))

```

## 4. Save the imputed data

```{r}

write.csv(imputed, "/home/jae/analyzing-racial-lived-experience/processed_data/imputed.csv")

```
